{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonnegative Matrix Factorization (NMF) for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package and codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the modules cointaning the algorithm we want to tests. File include_amf_new_1.py contains all the routines for the masked AMF (solved via accelerated PALM, see Alg. 5 in De Castro and Mencarelli (2024)), while in file include_nmf_new_1.py there are all the procedures for the masked NMF (solved via accelerated HALS, see Alg. 1 in De Castro and Mencarelli (2024)). Same for overlap versions of the codes. File include_benchmark.py conatins all the routine for the benchmark algorithms we are going to compare against mAMF and mNMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import random\n",
    "\n",
    "import include_amf_new_1 as amf\n",
    "import include_nmf_new_1 as nmf\n",
    "import include_amf_new_1_overlap as amf_overlap\n",
    "import include_nmf_new_1_overlap as nmf_overlap\n",
    "import include_benchmark as bmrk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import and pre-process the dataset. In this case, we consider the daily electricity consumptions of 370 Portuguese customers during the period 2011-2014, see Trindade (2015). We set the period to forecast (namely the last 28 days) and we save the values of our dataset in X_original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.parsers.read_csv('data/LD2011_2014.txt', sep=\";\", index_col=0, header=0, low_memory=False, decimal=',')\n",
    "df = data\n",
    "df = df.iloc[2*96:, :]\n",
    "df = df.iloc[:-1, :]\n",
    "df = df.iloc[:-3*96, :]\n",
    "\n",
    "df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "df = df.groupby(pd.Grouper(freq=\"D\")).sum()\n",
    "\n",
    "print(df)\n",
    "\n",
    "name = \"electricity_day_\"\n",
    "periods_to_forecast = 4*7\n",
    "X_original = df.transpose().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose parameters: W, P and K for NMF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the parameter for the mAMF and mNMF algorithms, namely the periodicity P, the number of the consecutive sub-blocks we want to pile in the same row and the ranks K for the NMF-like algorithms. The definition of \\Pi(M) is automatic and is contained in the include_amf_new_1*.py and include_nmf_new_1*.py files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_w1 = [4,13]\n",
    "list_rank1 = [5, 10, 20, 30, 40, 50]\n",
    "periodicity1 = 28\n",
    "\n",
    "list_w2 = [4,13]\n",
    "list_rank2 = [5, 10, 20, 30, 40, 50]\n",
    "periodicity2 = 2*periodicity1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run forecasting procedure based on NMF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define array RESULT which is going to contains all the performances for the algorithm we will test. Each row of RESULT variable refers to a given algorithm, in the columns we will stock the RRMSE and RMPE indices, and the total CPU time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT = [[] for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) mAMF without overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test mAMF without overlap solved by accelerated PALM. The input of amf.experiments_amf are the dataset values contained in X_original, the number of periods to forecast, the array containing the parameters W, the ranks K, and the periodicity P we want to consider in our experiments, and a string corresponding to the log file (in this latter file we print out all the performances in terms of RRMSE and RMPE indices, and total CPU time for each tuple (P,W,K)). The function amf.experiments_amf returns the best RRMSE and RPME indices among all the combinations of parameters and the corresponding CPU times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_best_rrmse_AMF, p_best_rrmse_AMF, best_error_rrmse_AMF, elapsed_time_rrmse_AMF, w_best_mpe_AMF, p_best_mpe_AMF, best_error_mpe_AMF, elapsed_time_mpe_AMF = amf.experiments_amf(X_original,periods_to_forecast,list_w1,list_rank1,periodicity1,name+\"log_file_AMF\")\n",
    "\n",
    "RESULT[1].append(\"AMF\")\n",
    "RESULT[1].append(best_error_rrmse_AMF)\n",
    "RESULT[1].append(elapsed_time_rrmse_AMF)\n",
    "RESULT[1].append(best_error_mpe_AMF)\n",
    "RESULT[1].append(elapsed_time_mpe_AMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) mAMF with overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test mAMF with overlap solved by accelerated PALM. The inputs and the outputs of amf_overlap.experiments_amf are the same as in 1) mAMF without overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_best_rrmse_AMF_OVERLAP, p_best_rrmse_AMF_OVERLAP, best_error_rrmse_AMF_OVERLAP, elapsed_time_rrmse_AMF_OVERLAP, w_best_mpe_AMF_OVERLAP, p_best_mpe_AMF_OVERLAP, best_error_mpe_AMF_OVERLAP, elapsed_time_mpe_AMF_OVERLAP = amf_overlap.experiments_amf(X_original,periods_to_forecast,list_w2,list_rank2,periodicity2,name+\"log_file_AMF_OVERLAP\")\n",
    "\n",
    "RESULT[2].append(\"AMF_OVERLAP\")\n",
    "RESULT[2].append(best_error_rrmse_AMF_OVERLAP)\n",
    "RESULT[2].append(elapsed_time_rrmse_AMF_OVERLAP)\n",
    "RESULT[2].append(best_error_mpe_AMF_OVERLAP)\n",
    "RESULT[2].append(elapsed_time_mpe_AMF_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) mNMF without overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test mNMF without overlap solved by accelerated HALS. The inputs and the outputs of nmf.experiments_amf are the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_best_rrmse_NMF, p_best_rrmse_NMF, best_error_rrmse_NMF, elapsed_time_rrmse_NMF, w_best_mpe_NMF, p_best_mpe_NMF, best_error_mpe_NMF, elapsed_time_mpe_NMF = nmf.experiments_amf(X_original,periods_to_forecast,list_w1,list_rank1,periodicity1,name+\"log_file_NMF\")\n",
    "\n",
    "RESULT[3].append(\"NMF\")\n",
    "RESULT[3].append(best_error_rrmse_NMF)\n",
    "RESULT[3].append(elapsed_time_rrmse_NMF)\n",
    "RESULT[3].append(best_error_mpe_NMF)\n",
    "RESULT[3].append(elapsed_time_mpe_NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) mNMF with overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test mNMF with overlap solved by accelerated HALS. The inputs and the outputs of nmf_overlap.experiments_amf are the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_best_rrmse_NMF_OVERLAP, p_best_rrmse_NMF_OVERLAP, best_error_rrmse_NMF_OVERLAP, elapsed_time_rrmse_NMF_OVERLAP, w_best_mpe_NMF_OVERLAP, p_best_mpe_NMF_OVERLAP, best_error_mpe_NMF_OVERLAP, elapsed_time_mpe_NMF_OVERLAP = nmf_overlap.experiments_amf(X_original,periods_to_forecast,list_w2,list_rank2,periodicity2,name+\"log_file_NMF_OVERLAP\")\n",
    "\n",
    "RESULT[4].append(\"NMF_OVERLAP\")\n",
    "RESULT[4].append(best_error_rrmse_NMF_OVERLAP)\n",
    "RESULT[4].append(elapsed_time_rrmse_NMF_OVERLAP)\n",
    "RESULT[4].append(best_error_mpe_NMF_OVERLAP)\n",
    "RESULT[4].append(elapsed_time_mpe_NMF_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Random Forest Regression (RFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test Random Forest Regression (RFR). The time series forecasting problem is converted into a supervised learning problem by splitting the sequance conating the past values in sub-sequences, see https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/, and RFR methodology is applied, see https://machinelearningmastery.com/random-forest-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_timeRFR, error_rrmseRFR, error_mpeRFR = bmrk.experiments_rfr(X_original,periods_to_forecast,periodicity1)\n",
    "\n",
    "RESULT[5].append(\"RFR\")\n",
    "RESULT[5].append(error_rrmseRFR)\n",
    "RESULT[5].append(elapsed_timeRFR)\n",
    "RESULT[5].append(error_mpeRFR)\n",
    "RESULT[5].append(elapsed_timeRFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Long Short-Term Memory (LSTM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test deep learning approach, namely Long Short-Term Memory (LSTM). The values are standardizated in (-1,1) and the time series forecasting problem is converted into a supervised learning problem as above, and LSTM methodology is applied, see https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_timeLSTM, error_rrmseLSTM, error_mpeLSTM = bmrk.experiments_neural_network_LSTM(X_original,periods_to_forecast,periodicity1)\n",
    "\n",
    "RESULT[6].append(\"LSTM\")\n",
    "RESULT[6].append(error_rrmseLSTM)\n",
    "RESULT[6].append(elapsed_timeLSTM)\n",
    "RESULT[6].append(error_mpeLSTM)\n",
    "RESULT[6].append(elapsed_timeLSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Gated Recurrent Units (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test deep learning approach, namely Gated Recurrent Units (GRU), see the reference in 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_timeGRU, error_rrmseGRU, error_mpeGRU = bmrk.experiments_neural_network_GRU(X_original,periods_to_forecast,periodicity1)\n",
    "\n",
    "RESULT[7].append(\"GRU\")\n",
    "RESULT[7].append(error_rrmseGRU)\n",
    "RESULT[7].append(elapsed_timeGRU)\n",
    "RESULT[7].append(error_mpeGRU)\n",
    "RESULT[7].append(elapsed_timeGRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Exponential Smoothing (EXP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test Exponential Smoothing (EXP), see https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_timeEXP, error_rrmseEXP, error_mpeEXP = bmrk.experiments_exponential_smoothing(X_original,periods_to_forecast,periodicity1)\n",
    "\n",
    "RESULT[8].append(\"EXP\")\n",
    "RESULT[8].append(error_rrmseEXP)\n",
    "RESULT[8].append(elapsed_timeEXP)\n",
    "RESULT[8].append(error_mpeEXP)\n",
    "RESULT[8].append(elapsed_timeEXP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Seasonal Auto-Regressive Integrated Moving Average with eXogenous factors (SARIMAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test Seasonal Auto-Regressive Integrated Moving Average with eXogenous factors (SARIMAX) by means of statsmodels.tsa.statespace.sarimax functions, see https://www.statsmodels.org/devel/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_timeSARIMAX, error_rrmseSARIMAX, error_mpeSARIMAX = bmrk.experiments_SARIMAX(X_original,periods_to_forecast,periodicity1)\n",
    "\n",
    "RESULT[9].append(\"SARIMAX\")\n",
    "RESULT[9].append(error_rrmseSARIMAX)\n",
    "RESULT[9].append(elapsed_timeSARIMAX)\n",
    "RESULT[9].append(error_mpeSARIMAX)\n",
    "RESULT[9].append(elapsed_timeSARIMAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output tables for NMF-like procedures and benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we print out the table containing all the results for the NMF-like procedures and for the benchmark algorithms we tested so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulate(RESULT, headers='firstrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
